# ðŸŽ¯ PLANO DE AÃ‡ÃƒO - REPROCESSAMENTO DA BASE DE CONHECIMENTO
**Data:** 08/08/2025  
**Prioridade:** ðŸ”´ CRÃTICA  
**Prazo:** IMEDIATO

---

## ðŸš¨ PROBLEMA PRINCIPAL

A base de conhecimento do Chat PD POA estÃ¡ com problemas crÃ­ticos que comprometem a precisÃ£o das respostas:

1. **Tabela regime_urbanÃ­stico desatualizada** - nÃ£o reflete dados da planilha Excel original
2. **Embeddings inconsistentes** - documentos DOCX usando mÃ©todos diferentes
3. **Falha em queries legais** - Artigos/Incisos nÃ£o sÃ£o recuperados corretamente
4. **FormataÃ§Ã£o inadequada** - respostas nÃ£o usam tabelas para dados complexos
5. **Sem aprendizagem** - sistema nÃ£o evolui com feedback

---

## ðŸ“‹ AÃ‡Ã•ES IMEDIATAS (EXECUTAR AGORA)

### PASSO 1: Backup Completo
```bash
# Criar backup de seguranÃ§a
pg_dump -h db.ngrqwmvuhvjkeohesbxs.supabase.co \
  -U postgres \
  -d postgres \
  --table=regime_urbanistico \
  --table=document_sections \
  --table=document_rows \
  > backup_knowledge_base_08082025.sql
```

### PASSO 2: Criar Script de Reprocessamento
```javascript
// scripts/reprocess-knowledge-base.mjs
import { createClient } from '@supabase/supabase-js';
import ExcelJS from 'exceljs';
import { Document } from 'langchain/document';
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';
import { OpenAIEmbeddings } from 'langchain/embeddings/openai';
import mammoth from 'mammoth';
import fs from 'fs/promises';
import path from 'path';

const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

class KnowledgeBaseProcessor {
  constructor() {
    this.embeddings = new OpenAIEmbeddings({
      openAIApiKey: process.env.OPENAI_API_KEY,
      modelName: 'text-embedding-3-small'
    });
    
    this.splitter = new RecursiveCharacterTextSplitter({
      chunkSize: 1000,
      chunkOverlap: 200,
      separators: ["\n\n", "\n", ".", "!", "?", ";", ":", " ", ""]
    });
  }

  // 1. Processar Regime UrbanÃ­stico do Excel
  async processRegimeUrbanistico() {
    console.log('ðŸ“Š Processando Regime UrbanÃ­stico...');
    
    const workbook = new ExcelJS.Workbook();
    await workbook.xlsx.readFile('knowledgebase/PDPOA2025-Regime_Urbanistico.xlsx');
    const worksheet = workbook.getWorksheet(1);
    
    // Limpar tabela existente
    await supabase.from('regime_urbanistico').delete().neq('id', 0);
    
    const records = [];
    worksheet.eachRow((row, rowNumber) => {
      if (rowNumber > 1) { // Skip header
        const record = {
          zona: row.getCell(1).value,
          bairro: row.getCell(2).value,
          altura_maxima: row.getCell(3).value,
          coef_aproveitamento_basico: row.getCell(4).value,
          coef_aproveitamento_maximo: row.getCell(5).value,
          // ... mapear todas as 57 colunas
        };
        records.push(record);
      }
    });
    
    // Inserir em lotes
    const batchSize = 50;
    for (let i = 0; i < records.length; i += batchSize) {
      const batch = records.slice(i, i + batchSize);
      const { error } = await supabase
        .from('regime_urbanistico')
        .insert(batch);
      
      if (error) {
        console.error('âŒ Erro ao inserir regime:', error);
      } else {
        console.log(`âœ… Inseridos ${batch.length} registros (${i + batch.length}/${records.length})`);
      }
    }
  }

  // 2. Processar Documentos DOCX com mÃ©todo unificado
  async processDocuments() {
    console.log('ðŸ“„ Processando documentos DOCX...');
    
    const docFiles = [
      'PDPOA2025-Minuta_Preliminar_LUOS.docx',
      'PDPOA2025-Minuta_Preliminar_PLANO_DIRETOR.docx',
      'PDPOA2025-Objetivos_Previstos.docx',
      'PDPOA2025-QA.docx'
    ];
    
    // Limpar embeddings existentes
    await supabase
      .from('document_sections')
      .delete()
      .in('source_file', docFiles);
    
    for (const file of docFiles) {
      console.log(`\nðŸ“– Processando ${file}...`);
      
      const filePath = path.join('knowledgebase', file);
      const buffer = await fs.readFile(filePath);
      const result = await mammoth.extractRawText({ buffer });
      const text = result.value;
      
      // Chunking hierÃ¡rquico para documentos legais
      const chunks = await this.hierarchicalChunking(text, file);
      
      // Gerar embeddings
      const embeddings = await this.generateEmbeddings(chunks);
      
      // Salvar no banco
      await this.saveEmbeddings(chunks, embeddings, file);
    }
  }

  // 3. Chunking hierÃ¡rquico otimizado para documentos legais
  async hierarchicalChunking(text, filename) {
    const chunks = [];
    
    // Detectar estrutura do documento
    const isLegalDoc = filename.includes('LUOS') || filename.includes('PLANO_DIRETOR');
    
    if (isLegalDoc) {
      // Processar por artigos/seÃ§Ãµes
      const articlePattern = /(?:ARTIGO|Art\.?)\s+(\d+)[ÂºÂ°]?\s*[-â€“]\s*(.+?)(?=(?:ARTIGO|Art\.?)\s+\d+|$)/gis;
      const matches = [...text.matchAll(articlePattern)];
      
      for (const match of matches) {
        const articleNum = match[1];
        const articleContent = match[0];
        
        // Preservar artigo completo se pequeno
        if (articleContent.length < 1500) {
          chunks.push({
            content: articleContent,
            metadata: {
              type: 'article',
              article_number: articleNum,
              source: filename
            }
          });
        } else {
          // Dividir artigos grandes por parÃ¡grafos/incisos
          const subChunks = await this.splitter.splitText(articleContent);
          subChunks.forEach((chunk, idx) => {
            chunks.push({
              content: chunk,
              metadata: {
                type: 'article_part',
                article_number: articleNum,
                part: idx + 1,
                source: filename
              }
            });
          });
        }
      }
    } else {
      // Chunking padrÃ£o para outros documentos
      const textChunks = await this.splitter.splitText(text);
      textChunks.forEach((chunk, idx) => {
        chunks.push({
          content: chunk,
          metadata: {
            type: 'standard',
            chunk_index: idx,
            source: filename
          }
        });
      });
    }
    
    return chunks;
  }

  // 4. Gerar embeddings em lote
  async generateEmbeddings(chunks) {
    const texts = chunks.map(c => c.content);
    const embeddings = [];
    
    // Processar em lotes de 20
    for (let i = 0; i < texts.length; i += 20) {
      const batch = texts.slice(i, i + 20);
      const batchEmbeddings = await this.embeddings.embedDocuments(batch);
      embeddings.push(...batchEmbeddings);
      
      console.log(`ðŸ”„ Embeddings gerados: ${embeddings.length}/${texts.length}`);
    }
    
    return embeddings;
  }

  // 5. Salvar embeddings com metadados ricos
  async saveEmbeddings(chunks, embeddings, sourceFile) {
    const records = chunks.map((chunk, idx) => ({
      content: chunk.content,
      embedding: embeddings[idx],
      metadata: {
        ...chunk.metadata,
        source_file: sourceFile,
        created_at: new Date().toISOString(),
        chunk_method: 'hierarchical',
        model: 'text-embedding-3-small'
      }
    }));
    
    // Inserir em lotes
    for (let i = 0; i < records.length; i += 50) {
      const batch = records.slice(i, i + 50);
      const { error } = await supabase
        .from('document_sections')
        .insert(batch);
      
      if (error) {
        console.error('âŒ Erro ao salvar embeddings:', error);
      } else {
        console.log(`âœ… Salvos ${batch.length} chunks (${i + batch.length}/${records.length})`);
      }
    }
  }

  // 6. Criar Ã­ndices otimizados
  async createIndexes() {
    console.log('ðŸ” Criando Ã­ndices otimizados...');
    
    const indexes = [
      // Ãndice para busca de artigos
      `CREATE INDEX IF NOT EXISTS idx_document_sections_articles 
       ON document_sections USING gin(to_tsvector('portuguese', content))`,
      
      // Ãndice para metadados
      `CREATE INDEX IF NOT EXISTS idx_document_sections_metadata 
       ON document_sections USING gin(metadata jsonb_path_ops)`,
      
      // Ãndice para busca vetorial
      `CREATE INDEX IF NOT EXISTS idx_document_sections_embedding 
       ON document_sections USING ivfflat (embedding vector_cosine_ops) 
       WITH (lists = 100)`,
      
      // Ãndice para regime urbanÃ­stico
      `CREATE INDEX IF NOT EXISTS idx_regime_zona_bairro 
       ON regime_urbanistico(zona, bairro)`,
      
      `CREATE INDEX IF NOT EXISTS idx_regime_bairro 
       ON regime_urbanistico(bairro)`
    ];
    
    for (const index of indexes) {
      const { error } = await supabase.rpc('execute_sql', { query: index });
      if (error) {
        console.error('âŒ Erro ao criar Ã­ndice:', error);
      } else {
        console.log('âœ… Ãndice criado com sucesso');
      }
    }
  }

  // Executar todo o processo
  async run() {
    console.log('ðŸš€ Iniciando reprocessamento da base de conhecimento...\n');
    
    try {
      // 1. Processar regime urbanÃ­stico
      await this.processRegimeUrbanistico();
      
      // 2. Processar documentos
      await this.processDocuments();
      
      // 3. Criar Ã­ndices
      await this.createIndexes();
      
      console.log('\nâœ… Reprocessamento concluÃ­do com sucesso!');
      
      // EstatÃ­sticas finais
      const { count: regimeCount } = await supabase
        .from('regime_urbanistico')
        .select('*', { count: 'exact', head: true });
      
      const { count: sectionsCount } = await supabase
        .from('document_sections')
        .select('*', { count: 'exact', head: true });
      
      console.log('\nðŸ“Š EstatÃ­sticas:');
      console.log(`- Registros de regime urbanÃ­stico: ${regimeCount}`);
      console.log(`- SeÃ§Ãµes de documentos: ${sectionsCount}`);
      
    } catch (error) {
      console.error('âŒ Erro no reprocessamento:', error);
      process.exit(1);
    }
  }
}

// Executar
const processor = new KnowledgeBaseProcessor();
processor.run();
```

### PASSO 3: Instalar DependÃªncias
```bash
npm install exceljs mammoth langchain @langchain/openai
```

### PASSO 4: Executar Reprocessamento
```bash
# Definir variÃ¡veis de ambiente
export SUPABASE_URL="https://ngrqwmvuhvjkeohesbxs.supabase.co"
export SUPABASE_SERVICE_ROLE_KEY="[YOUR_SERVICE_ROLE_KEY]"
export OPENAI_API_KEY="[YOUR_OPENAI_KEY]"

# Executar script
node scripts/reprocess-knowledge-base.mjs
```

---

## ðŸ”§ MELHORIAS NO PIPELINE RAG

### 1. Atualizar Query Analyzer
```typescript
// supabase/functions/query-analyzer/index.ts

// Adicionar patterns mais robustos para queries legais
const enhancedLegalPatterns = [
  // Artigos
  /\bart(?:igo)?\.?\s*(\d+)/gi,
  /\bart(?:igo)?\.?\s*(\d+)[ÂºÂ°]?/gi,
  
  // Incisos
  /\binciso\s+([IVXLCDM]+|\d+)/gi,
  /\bÂ§\s*(\d+)[ÂºÂ°]?/gi,
  
  // ParÃ¡grafos
  /\bpar[aÃ¡]grafo\s+(\d+|[Ãºu]nico)/gi,
  
  // AlÃ­neas
  /\bal[Ã­i]nea\s+([a-z])/gi,
  
  // Leis e decretos
  /\blei\s+(?:complementar\s+)?n[ÂºÂ°]?\s*(\d+)/gi,
  /\bdecreto\s+n[ÂºÂ°]?\s*(\d+)/gi,
  
  // Termos especÃ­ficos do PDUS
  /\bcertifica[Ã§c][Ã£a]o.*sustentabilidade/gi,
  /\b4[ÂºÂ°]?\s*distrito/gi,
  /\boutorga\s+onerosa/gi,
  /\bzeis\b/gi,
  /\beiv\b/gi,
  /\binstrumentos.*pol[Ã­i]tica.*urbana/gi
];

// Melhorar extraÃ§Ã£o de entidades
function extractLegalEntities(query: string) {
  const entities = {
    articles: [],
    paragraphs: [],
    laws: [],
    specificTerms: []
  };
  
  // Extrair nÃºmeros de artigos
  const articleMatches = query.matchAll(/\bart(?:igo)?\.?\s*(\d+)/gi);
  for (const match of articleMatches) {
    entities.articles.push(parseInt(match[1]));
  }
  
  // Extrair referÃªncias de leis
  const lawMatches = query.matchAll(/\blei\s+(?:complementar\s+)?n[ÂºÂ°]?\s*(\d+)/gi);
  for (const match of lawMatches) {
    entities.laws.push(match[1]);
  }
  
  return entities;
}
```

### 2. Melhorar Vector Search
```typescript
// supabase/functions/enhanced-vector-search/index.ts

// ExpansÃ£o de query para termos legais
function expandLegalQuery(query: string): string {
  const expansions = {
    'certificaÃ§Ã£o sustentabilidade': [
      'artigo 81',
      'inciso III',
      'certificaÃ§Ã£o de sustentabilidade ambiental',
      'acrÃ©scimos no potencial construtivo'
    ],
    '4Âº distrito': [
      'artigo 74',
      'quarto distrito',
      'ZOT 8.2',
      'revitalizaÃ§Ã£o urbana',
      'Ã¡rea de transformaÃ§Ã£o'
    ],
    'outorga onerosa': [
      'artigo 86',
      'direito de construir',
      'contrapartida financeira',
      'solo criado'
    ],
    'zeis': [
      'artigo 92',
      'zonas especiais de interesse social',
      'habitaÃ§Ã£o de interesse social',
      'regularizaÃ§Ã£o fundiÃ¡ria'
    ]
  };
  
  let expandedQuery = query;
  
  for (const [term, synonyms] of Object.entries(expansions)) {
    if (query.toLowerCase().includes(term)) {
      expandedQuery += ' ' + synonyms.join(' ');
    }
  }
  
  return expandedQuery;
}

// Busca hÃ­brida: keyword + semantic
async function hybridSearch(query: string, limit: number = 10) {
  // 1. Busca por palavras-chave
  const keywordResults = await supabase
    .from('document_sections')
    .select('*')
    .textSearch('content', query, {
      type: 'websearch',
      config: 'portuguese'
    })
    .limit(limit);
  
  // 2. Busca semÃ¢ntica
  const embedding = await generateEmbedding(query);
  const semanticResults = await supabase
    .rpc('match_documents', {
      query_embedding: embedding,
      match_threshold: 0.7,
      match_count: limit
    });
  
  // 3. Combinar e re-ranquear
  return reRankResults(keywordResults.data, semanticResults.data);
}
```

### 3. Implementar Response Formatter
```typescript
// supabase/functions/response-synthesizer/index.ts

class ResponseFormatter {
  formatRegimeData(data: any[]): string {
    if (!data || data.length === 0) return '';
    
    // Agrupar por zona
    const byZone = data.reduce((acc, item) => {
      if (!acc[item.zona]) acc[item.zona] = [];
      acc[item.zona].push(item);
      return acc;
    }, {});
    
    let formatted = '## ðŸ“Š Regime UrbanÃ­stico\n\n';
    
    for (const [zona, items] of Object.entries(byZone)) {
      formatted += `### ${zona}\n\n`;
      formatted += '| Bairro | Altura MÃ¡x | Coef. BÃ¡sico | Coef. MÃ¡ximo |\n';
      formatted += '|--------|------------|--------------|---------------|\n';
      
      for (const item of items) {
        formatted += `| ${item.bairro} | ${item.altura_maxima}m | ${item.coef_aproveitamento_basico} | ${item.coef_aproveitamento_maximo} |\n`;
      }
      formatted += '\n';
    }
    
    return formatted;
  }
  
  formatLegalReference(article: number, content: string): string {
    return `
ðŸ“œ **Artigo ${article}**

${content}

---
*Fonte: Plano Diretor de Porto Alegre - PDUS 2025*
    `;
  }
}
```

---

## ðŸ§ª TESTES DE VALIDAÃ‡ÃƒO

### Script de Teste Completo
```javascript
// scripts/validate-reprocessing.mjs

const testCases = [
  // Teste 1: Regime UrbanÃ­stico
  {
    query: "Qual a altura mÃ¡xima no bairro Centro?",
    expectedFields: ['altura_maxima', 'zona', 'coef_aproveitamento_basico']
  },
  
  // Teste 2: Artigos Legais
  {
    query: "O que diz o artigo 81 sobre certificaÃ§Ã£o de sustentabilidade?",
    expectedContent: ['certificaÃ§Ã£o', 'sustentabilidade', 'inciso III']
  },
  
  // Teste 3: Query Complexa
  {
    query: "Quais sÃ£o as regras para construÃ§Ã£o no 4Âº distrito?",
    expectedContent: ['artigo 74', 'ZOT 8.2', 'revitalizaÃ§Ã£o']
  },
  
  // Teste 4: FormataÃ§Ã£o de Tabela
  {
    query: "Compare o regime urbanÃ­stico dos bairros Moinhos de Vento e PetrÃ³polis",
    expectedFormat: 'table',
    expectedBairros: ['Moinhos de Vento', 'PetrÃ³polis']
  }
];

async function runValidation() {
  console.log('ðŸ§ª Iniciando validaÃ§Ã£o do reprocessamento...\n');
  
  let passed = 0;
  let failed = 0;
  
  for (const test of testCases) {
    const response = await fetch('https://ngrqwmvuhvjkeohesbxs.supabase.co/functions/v1/agentic-rag', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.SUPABASE_ANON_KEY}`
      },
      body: JSON.stringify({ query: test.query })
    });
    
    const result = await response.json();
    
    // Validar resposta
    let testPassed = true;
    
    if (test.expectedFields) {
      for (const field of test.expectedFields) {
        if (!result.response.includes(field)) {
          testPassed = false;
          console.log(`âŒ Falhou: Campo '${field}' nÃ£o encontrado`);
        }
      }
    }
    
    if (test.expectedContent) {
      for (const content of test.expectedContent) {
        if (!result.response.toLowerCase().includes(content.toLowerCase())) {
          testPassed = false;
          console.log(`âŒ Falhou: ConteÃºdo '${content}' nÃ£o encontrado`);
        }
      }
    }
    
    if (testPassed) {
      console.log(`âœ… Passou: ${test.query}`);
      passed++;
    } else {
      console.log(`âŒ Falhou: ${test.query}`);
      failed++;
    }
  }
  
  console.log(`\nðŸ“Š Resultados: ${passed} passou, ${failed} falhou`);
  console.log(`Taxa de sucesso: ${(passed / testCases.length * 100).toFixed(1)}%`);
}

runValidation();
```

---

## ðŸ“Š MONITORAMENTO PÃ“S-REPROCESSAMENTO

### Dashboard de MÃ©tricas
```sql
-- Criar view para monitoramento
CREATE OR REPLACE VIEW v_knowledge_base_metrics AS
SELECT 
  'regime_urbanistico' as source,
  COUNT(*) as total_records,
  COUNT(DISTINCT zona) as unique_zones,
  COUNT(DISTINCT bairro) as unique_bairros
FROM regime_urbanistico

UNION ALL

SELECT 
  'document_sections' as source,
  COUNT(*) as total_records,
  COUNT(DISTINCT metadata->>'source_file') as unique_files,
  AVG(LENGTH(content)) as avg_content_length
FROM document_sections;

-- Query para verificar saÃºde do sistema
SELECT * FROM v_knowledge_base_metrics;
```

### Alertas AutomÃ¡ticos
```javascript
// scripts/monitor-health.mjs

async function checkSystemHealth() {
  const checks = {
    regime_count: { min: 387, actual: 0 },
    sections_count: { min: 1000, actual: 0 },
    avg_response_time: { max: 3000, actual: 0 },
    error_rate: { max: 0.1, actual: 0 }
  };
  
  // Verificar contagens
  const { count: regimeCount } = await supabase
    .from('regime_urbanistico')
    .select('*', { count: 'exact', head: true });
  checks.regime_count.actual = regimeCount;
  
  // Enviar alerta se problemas
  for (const [metric, values] of Object.entries(checks)) {
    if (values.min && values.actual < values.min) {
      console.error(`âš ï¸ ALERTA: ${metric} abaixo do mÃ­nimo (${values.actual} < ${values.min})`);
    }
    if (values.max && values.actual > values.max) {
      console.error(`âš ï¸ ALERTA: ${metric} acima do mÃ¡ximo (${values.actual} > ${values.max})`);
    }
  }
}

// Executar a cada 5 minutos
setInterval(checkSystemHealth, 5 * 60 * 1000);
```

---

## âœ… CHECKLIST DE EXECUÃ‡ÃƒO

### PreparaÃ§Ã£o (10 min)
- [ ] Fazer backup do banco de dados
- [ ] Instalar dependÃªncias necessÃ¡rias
- [ ] Configurar variÃ¡veis de ambiente
- [ ] Revisar scripts antes de executar

### ExecuÃ§Ã£o (2-3 horas)
- [ ] Executar script de reprocessamento
- [ ] Monitorar logs durante execuÃ§Ã£o
- [ ] Verificar contagens apÃ³s cada etapa
- [ ] Criar Ã­ndices no banco

### ValidaÃ§Ã£o (30 min)
- [ ] Executar testes de validaÃ§Ã£o
- [ ] Testar queries problemÃ¡ticas manualmente
- [ ] Verificar formataÃ§Ã£o de respostas
- [ ] Confirmar taxa de sucesso > 80%

### DocumentaÃ§Ã£o (15 min)
- [ ] Atualizar documentaÃ§Ã£o tÃ©cnica
- [ ] Registrar mudanÃ§as realizadas
- [ ] Comunicar equipe sobre melhorias
- [ ] Agendar prÃ³xima revisÃ£o

---

## ðŸš€ COMANDO ÃšNICO PARA EXECUÃ‡ÃƒO

```bash
# Script all-in-one
cat > reprocess-all.sh << 'EOF'
#!/bin/bash

echo "ðŸš€ Iniciando reprocessamento completo..."

# 1. Backup
echo "ðŸ“¦ Fazendo backup..."
pg_dump -h db.ngrqwmvuhvjkeohesbxs.supabase.co \
  -U postgres -d postgres \
  --table=regime_urbanistico \
  --table=document_sections \
  > backup_$(date +%Y%m%d_%H%M%S).sql

# 2. Instalar dependÃªncias
echo "ðŸ“¦ Instalando dependÃªncias..."
npm install exceljs mammoth langchain @langchain/openai

# 3. Reprocessar
echo "ðŸ”„ Reprocessando base de conhecimento..."
node scripts/reprocess-knowledge-base.mjs

# 4. Validar
echo "ðŸ§ª Validando reprocessamento..."
node scripts/validate-reprocessing.mjs

# 5. Monitorar
echo "ðŸ“Š Iniciando monitoramento..."
node scripts/monitor-health.mjs &

echo "âœ… Reprocessamento completo!"
EOF

chmod +x reprocess-all.sh
./reprocess-all.sh
```

---

*Plano de aÃ§Ã£o criado em 08/08/2025 Ã s 14:00 PM*  
*ExecuÃ§Ã£o recomendada: IMEDIATA*  
*Suporte: equipe-dev@chatpdpoa.com*