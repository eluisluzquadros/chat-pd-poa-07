{
  "name": "TheAIAutomators.com - RAG Advanced Metadata - Supabase - BLUEPRINT 1.1 copy",
  "nodes": [
    {
      "parameters": {
        "content": "# Rag Agent\nChat to your Documents!",
        "height": 180,
        "width": 280,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -48,
        4208
      ],
      "id": "698281fd-b9ab-407b-825f-0fe11b83816a",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        192,
        4528
      ],
      "id": "b05120b1-3b11-4a68-9234-19ede38ea50f",
      "name": "When chat message received",
      "webhookId": "6548db9e-50e1-4d99-b3b2-b22c9c94b54d"
    },
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            {
              "name": "query"
            },
            {
              "name": "session_id"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        -416,
        5232
      ],
      "id": "e5fecc29-f289-49de-84d9-7839e0c7ca44",
      "name": "When Executed by Another Workflow"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "71326cd6-1316-4b5e-bf34-0d0b3c086005",
              "leftValue": "={{ $('Trigger Hybrid Search1').item.json.keys().length}}",
              "rightValue": 0,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1712,
        5232
      ],
      "id": "02c340de-f915-47b5-945d-aa9d53ae3eac",
      "name": "If3",
      "alwaysOutputData": false
    },
    {
      "parameters": {
        "jsCode": "return [{\n  message: \"no documents found\" \n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1872,
        5360
      ],
      "id": "b1280bda-d27e-4b8f-b006-9d3c457303c2",
      "name": "Code"
    },
    {
      "parameters": {
        "options": {
          "groupMessages": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.memoryManager",
      "typeVersion": 1.1,
      "position": [
        -160,
        5232
      ],
      "id": "554235f9-a914-4a42-8fbe-7b0d67cf7ecb",
      "name": "Chat Memory Manager",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "={{ $('When Executed by Another Workflow').item.json.session_id }}"
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        -128,
        5424
      ],
      "id": "9102dfac-0302-4158-834f-7219e51dfd89",
      "name": "Simple Memory1"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('When chat message received').item.json.chatInput }}",
        "options": {
          "systemMessage": "=You are tasked with answering a question using the information retrieved from the attached vector store.\n\nYour goal is to provide an accurate answer based on this information ONLY.\n\nIf you cannot answer the question using the provided information or if no information is returned from the vector store, say \"Sorry I don't know\"."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        400,
        4528
      ],
      "id": "20bd2c72-52a3-4db5-93b5-020e26b04df6",
      "name": "AI Agent1"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.4
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        352,
        4784
      ],
      "id": "a4067eb1-6a72-4913-ba9d-60c3c3bdb4d5",
      "name": "OpenAI Chat Model3"
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "={{ $('When chat message received').item.json.sessionId }}",
        "contextWindowLength": 20
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        512,
        4784
      ],
      "id": "6d675cf6-8f57-4963-bd8e-e476436f97ec",
      "name": "Simple Memory2"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-4.1",
          "mode": "list",
          "cachedResultName": "gpt-4.1"
        },
        "options": {
          "temperature": 0.4
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        688,
        5440
      ],
      "id": "129840e9-da2b-4f0f-8844-39977e4620be",
      "name": "OpenAI Chat Model4"
    },
    {
      "parameters": {
        "content": "## Hybrid Search with Reranking & Multiple Metadata Filters",
        "height": 80,
        "width": 720,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        144,
        4992
      ],
      "id": "409ed73f-eced-4ce2-b7d7-6bc6b6de15aa",
      "name": "Sticky Note9"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=# User Query\n{{ $('When Executed by Another Workflow').first().json.query }}\n\n# Conversation History (if any)\n{{ JSON.stringify($('Chat Memory Manager').first().json) }}",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "=# Task\n\nYour task is to consider the following user query and then consider the following metadata keys with example values that we have that we can limit our result set from.\n\n# Metadata Filters and Possible Values\n\n{{ $json.filterPromptInstructions }}\n\n# Metadata Operators\n\nThe following operators are allowed:\n\n>\n<\n=\n!=\n>=\n<=\nIN\nNOT IN\n\nIF IN or NOT IN are provided, then an array of values must be provided.\n\nNow output a filter array with relevant filters with the following example format. The below filter_categories are just for exampe purposes. Use the \"Metadata Filters and Possible Values\" list above for the list of allowed filters.\n\n[\n    \"filter\": {\n      \"$and\": [\n        {\n          \"category\": {\n            \"operator\": \"IN\",\n            \"value\": [\n              \"F1\",\n              \"Rally\"\n            ]\n          }\n        },\n        {\n          \"year\": {\n            \"operator\": \">\",\n            \"value\": 2024\n          }\n        }\n      ]\n    }\n]\n\nIf the query does not have relevant metadatafilters, then do not output any ... for example\n\n{\n  \"filter\": {}\n}\n\nIf there is only 1 relevant metadafilter, then just output that ... for example\n\n[\n    \"filter\": {\n      \"$and\": [\n        {\n          \"motorsport_category\": {\n            \"operator\": \"IN\",\n            \"value\": [\n              \"F1\",\n              \"Rally\"\n            ]\n          }\n        }\n      ]\n    }\n]\n\nOnly output in JSON"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.6,
      "position": [
        688,
        5232
      ],
      "id": "93ddedda-23d1-4178-841b-2010761f14c7",
      "name": "Prep Metadata1"
    },
    {
      "parameters": {
        "name": "Query_Vector_Store",
        "description": "Call this to fetch data from our vector store knowledgebase",
        "workflowId": {
          "__rl": true,
          "value": "nSav5gpI12iGXSLB",
          "mode": "list",
          "cachedResultName": "TheAIAutomators.com - RAG Advanced Metadata - Supabase - BLUEPRINT 1.1"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "query": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('query', ``, 'string') }}",
            "session_id": "={{ $('When chat message received').item.json.sessionId }}"
          },
          "matchingColumns": [
            "query"
          ],
          "schema": [
            {
              "id": "query",
              "displayName": "query",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            },
            {
              "id": "session_id",
              "displayName": "session_id",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "type": "string",
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2.1,
      "position": [
        688,
        4784
      ],
      "id": "acab2449-a8b9-4c36-80e8-991f09ba3f25",
      "name": "Query Vector Store1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/embeddings",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "input",
              "value": "={{ $('When Executed by Another Workflow').first().json.query }}"
            },
            {
              "name": "model",
              "value": "text-embedding-3-small"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1152,
        5232
      ],
      "id": "602e67d3-feeb-4320-8b28-a1f98f775920",
      "name": "Generate Embedding From Query1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.cohere.com/v2/rerank",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "accept",
              "value": "application/json"
            },
            {
              "name": "Authorization",
              "value": "bearer COHERE_KEY"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"model\": \"rerank-v3.5\",\n  \"query\": \"{{ $('When Executed by Another Workflow').first().json.query }}\",\n  \"top_n\": 5,\n  \"documents\": {{ JSON.stringify($json.documents) }}\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2288,
        5232
      ],
      "id": "ddb26040-534f-4620-afe4-98b8cb7ea712",
      "name": "Rerank with Cohere 3."
    },
    {
      "parameters": {
        "jsCode": "// --- This Code Node extracts 'content' from multiple input items ---\n\n// Step 1: Use .map() to iterate over ALL incoming items ($input.all()).\n// For each item, access its 'json' property, and then the 'content' field within that.\nconst contentArray = $input.all().map(item => {\n  // Basic safety check: ensure item.json and item.json.content exist.\n  // Return null or an empty string if not found, otherwise return the content.\n  // Adjust the fallback value (null) if needed.\n  return item.json?.content ?? null;\n});\n\n// Step 2: Filter out any potential null values if an item was missing content (optional)\n// If you are certain all items will have content, you can skip this filter.\nconst validContentArray = contentArray.filter(content => content !== null);\n\n// Step 3: Return the result as a *single* new n8n item.\n// This item contains your final array of strings under the 'documents' key.\nreturn [{\n  json: {\n    // Use validContentArray if you filtered, otherwise use contentArray\n    documents: validContentArray\n    // documents: contentArray // <-- Use this if you didn't filter\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2048,
        5232
      ],
      "id": "f2c9c11f-a0e5-4d04-b3fa-d7640a43776f",
      "name": "Create Array1"
    },
    {
      "parameters": {
        "jsCode": "// --- Code Node to Reorder Items Based on Rerank Results ---\n\n// --- Step 1: Get Data from Input Nodes ---\n// Using the input lines confirmed by the user as correct for their workflow.\n\n// Get the data array to be reordered from the 'Setup Array' node.\n// This could be an array of objects OR an array of strings.\nconst originalDataItems = $('Create Array1').first().json.documents;\n\n// Get the rerank results array from the primary input node's first item.\n// (Assumed to be the Cohere Rerank node output).\nconst rerankOrderInfo = $input.first().json.results;\n\n// --- Step 2: Validate Inputs (Basic Checks) ---\n// Validate that we actually got arrays to work with.\nif (!Array.isArray(originalDataItems)) {\n  throw new Error(\"Data retrieved from $('Setup Array').first().json.documents is not an array. Check the 'Setup Array' node output.\");\n}\nif (!Array.isArray(rerankOrderInfo) || rerankOrderInfo.length === 0) {\n  // Allow rerankOrderInfo to be empty if originalDataItems is also empty\n  if (originalDataItems.length !== 0) {\n      throw new Error(\"Could not get valid rerank results from the input node ($input.first()), but original data exists. Check the node providing rerank data.\");\n  }\n  // If both are empty, allow it to proceed and return empty.\n}\n\n\n// --- Step 3: Create the New Array in the Reranked Order ---\n// Handle the case where inputs might be empty.\nlet sortedData = [];\nif (rerankOrderInfo && rerankOrderInfo.length > 0 && originalDataItems && originalDataItems.length > 0) {\n    // Iterate through the rerankOrderInfo array. Each element tells us\n    // the index of the item we want from the originalDataItems array.\n    sortedData = rerankOrderInfo.map(rankInfo => {\n      const originalIndex = rankInfo.index;\n\n      // Check if the index is valid for the originalDataItems array\n      if (originalIndex !== undefined && originalIndex !== null && originalIndex >= 0 && originalIndex < originalDataItems.length) {\n        // Retrieve the corresponding original data item (object or string)\n        return originalDataItems[originalIndex];\n      } else {\n        // Log error for invalid index found in rerank results\n        console.error(`Error: Rerank result index ${originalIndex} is invalid or out of bounds for original data (length ${originalDataItems.length}). Skipping this index.`);\n        return null; // Return null for invalid indices\n      }\n    }).filter(item => item !== null); // Remove any nulls caused by invalid indices\n} else {\n    // If inputs were empty or invalid, ensure sortedData is an empty array\n    sortedData = [];\n    console.log(\"Input data (original or rerank info) is empty or invalid, resulting in empty sorted output.\");\n}\n\n\n// --- Step 4: Return the Sorted Data as a Single Item Containing the Array ---\n// This format returns ONE n8n item. The item's json property contains\n// an object with a key 'sortedDocuments' which holds the array.\n// This structure works correctly whether sortedData contains objects or strings.\nreturn [{\n  json: {\n    sortedDocuments: sortedData\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2512,
        5232
      ],
      "id": "270a2bf9-f22b-4d09-998e-6c024479e07c",
      "name": "Return Reordered Items"
    },
    {
      "parameters": {
        "content": "## Hybrid Search",
        "height": 300,
        "width": 520,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1072,
        5152
      ],
      "id": "db4143aa-7887-4c03-97a3-0de8f73d5d24",
      "name": "Sticky Note13"
    },
    {
      "parameters": {
        "content": "## Reranking Model",
        "height": 300,
        "width": 680,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        2000,
        5152
      ],
      "id": "ff3c84ff-a42f-424b-a7bc-f89e369326d6",
      "name": "Sticky Note14"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://mkrfwcplubvqbtqoytsd.supabase.co/functions/v1/hybrid-search",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer SUPABASE_KEY"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n        \"query_text\": \"{{ $('When Executed by Another Workflow').first().json.query }}\",\n        \"query_embedding\": [{{ $json.data[0].embedding }}],\n        \"match_count\": 5,\n        \"filter\": {{ JSON.stringify($('Prep Metadata1').item.json.output.filter) }}\n      }",
        "options": {
          "redirect": {
            "redirect": {}
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1424,
        5232
      ],
      "id": "5a42ecf5-32a9-4d8a-84a9-ed09ce8604f7",
      "name": "Trigger Hybrid Search1",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "operation": "getAll",
        "tableId": "metadata_fields"
      },
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        208,
        5232
      ],
      "id": "f40d68a5-e766-4349-867c-0e5a0fdb9b7e",
      "name": "Get many rows"
    },
    {
      "parameters": {
        "jsCode": "// Get input items\nconst items = $input.all();\n\n// Initialize output string\nlet output = '';\n\n// Loop through each input item\nfor (const item of items) {\n  const data = item.json;\n\n  const key = data.metadata_name;\n  const values = data.allowed_values;\n\n  output += `## ${key}\\n`;\n  output += `The filter key ${key} can have the following possible values\\n\\n`;\n  output += `${values.trim()}\\n\\n`;\n}\n\n// Return result\nreturn [\n  {\n    json: {\n      filterPromptInstructions: output.trim(),\n    }\n  }\n];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        432,
        5232
      ],
      "id": "422dc4a1-684f-4b93-885d-79a071cd2e0d",
      "name": "Code1"
    },
    {
      "parameters": {
        "schemaType": "manual",
        "inputSchema": "{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"title\": \"FlexibleFilterObject\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"filter\": {\n      \"type\": \"object\",\n      \"oneOf\": [\n        {\n          \"required\": [\"$and\"],\n          \"properties\": {\n            \"$and\": {\n              \"type\": \"array\",\n              \"items\": { \"$ref\": \"#/definitions/condition\" }\n            }\n          },\n          \"additionalProperties\": false\n        },\n        {\n          \"required\": [\"$or\"],\n          \"properties\": {\n            \"$or\": {\n              \"type\": \"array\",\n              \"items\": { \"$ref\": \"#/definitions/condition\" }\n            }\n          },\n          \"additionalProperties\": false\n        },\n        {\n          \"properties\": {},\n          \"additionalProperties\": false\n        }\n      ]\n    }\n  },\n  \"required\": [\"filter\"],\n  \"definitions\": {\n    \"condition\": {\n      \"oneOf\": [\n        {\n          \"type\": \"object\",\n          \"required\": [\"field\", \"operator\", \"value\"],\n          \"properties\": {\n            \"field\": { \"type\": \"string\" },\n            \"operator\": {\n              \"type\": \"string\",\n              \"enum\": [\"=\", \"!=\", \">\", \"<\", \">=\", \"<=\", \"IN\", \"NOT IN\"]\n            },\n            \"value\": {\n              \"oneOf\": [\n                { \"type\": \"string\" },\n                { \"type\": \"number\" },\n                {\n                  \"type\": \"array\",\n                  \"items\": { \"type\": [\"string\", \"number\"] }\n                }\n              ]\n            }\n          },\n          \"additionalProperties\": false\n        },\n        {\n          \"type\": \"object\",\n          \"minProperties\": 1,\n          \"maxProperties\": 1,\n          \"patternProperties\": {\n            \"^.+$\": {\n              \"type\": \"object\",\n              \"required\": [\"operator\", \"value\"],\n              \"properties\": {\n                \"operator\": {\n                  \"type\": \"string\",\n                  \"enum\": [\"=\", \"!=\", \">\", \"<\", \">=\", \"<=\", \"IN\", \"NOT IN\"]\n                },\n                \"value\": {\n                  \"oneOf\": [\n                    { \"type\": \"string\" },\n                    { \"type\": \"number\" },\n                    {\n                      \"type\": \"array\",\n                      \"items\": { \"type\": [\"string\", \"number\"] }\n                    }\n                  ]\n                }\n              },\n              \"additionalProperties\": false\n            }\n          },\n          \"additionalProperties\": false\n        }\n      ]\n    }\n  }\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        848,
        5440
      ],
      "id": "357f656f-57cd-4472-b497-9679068fead5",
      "name": "Structured Output Parser2"
    }
  ],
  "pinData": {},
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "AI Agent1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When Executed by Another Workflow": {
      "main": [
        [
          {
            "node": "Chat Memory Manager",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If3": {
      "main": [
        [
          {
            "node": "Create Array1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chat Memory Manager": {
      "main": [
        [
          {
            "node": "Get many rows",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory1": {
      "ai_memory": [
        [
          {
            "node": "Chat Memory Manager",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory2": {
      "ai_memory": [
        [
          {
            "node": "AI Agent1",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Prep Metadata1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prep Metadata1": {
      "main": [
        [
          {
            "node": "Generate Embedding From Query1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Query Vector Store1": {
      "ai_tool": [
        [
          {
            "node": "AI Agent1",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Generate Embedding From Query1": {
      "main": [
        [
          {
            "node": "Trigger Hybrid Search1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Rerank with Cohere 3.": {
      "main": [
        [
          {
            "node": "Return Reordered Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Array1": {
      "main": [
        [
          {
            "node": "Rerank with Cohere 3.",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Trigger Hybrid Search1": {
      "main": [
        [
          {
            "node": "If3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get many rows": {
      "main": [
        [
          {
            "node": "Code1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code1": {
      "main": [
        [
          {
            "node": "Prep Metadata1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser2": {
      "ai_outputParser": [
        [
          {
            "node": "Prep Metadata1",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "9a4cf9fa-d5f1-4238-9db7-709eb98e3204",
  "meta": {
    "instanceId": "f2f2958b1248201385f5d1061b53f3a43b83d6ad716089d447c2339c5faf20cf"
  },
  "id": "MGT1zvN6VWfovVaB",
  "tags": []
}